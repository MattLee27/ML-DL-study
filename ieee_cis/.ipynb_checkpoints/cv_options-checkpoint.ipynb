{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IEEE-CV options\n",
    "- [IEEE - CV options](https://www.kaggle.com/kyakovlev/ieee-cv-options)\n",
    "- 모델링은 lightGBM\n",
    "- 여러 cross validation 모델 모으고, 시계열 데이터 반영(뒷부분)\n",
    "- 이것도 결국 [data minification](https://www.kaggle.com/kyakovlev/ieee-data-minification) 참고한 커널. 일단 원 데이터로 해 보기\n",
    "- 여기서 궁금한 점\n",
    "    - train의 일부를 test라는 이름으로 뗀 것(val set인가?)\n",
    "    - DT_M의 최대값(17)인 데이터를 test로 뗀 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input\\df_id.pkl\n",
      "../input\\df_pca.pkl\n",
      "../input\\df_test.pkl\n",
      "../input\\df_train.pkl\n",
      "../input\\df_trans.pkl\n",
      "../input\\sample_submission.csv\n",
      "../input\\test.pkl\n",
      "../input\\test_0823.pkl\n",
      "../input\\test_identity.csv\n",
      "../input\\test_transaction.csv\n",
      "../input\\train_0823.pkl\n",
      "../input\\train_identity.csv\n",
      "../input\\train_transaction.csv\n"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, warnings, random, datetime\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "\n",
    "import math\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for dirname, _, filenames in os.walk(\"../input\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 41\n",
    "seed_everything(SEED)\n",
    "TARGET = 'isFraud'\n",
    "START_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These parameters we will keep untouched\n",
    "# for each lgbm model\n",
    "# the unique param that we will look at\n",
    "# is n_estimators\n",
    "lgb_params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators':2000,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':-1,\n",
    "                    'seed': SEED,\n",
    "                    'early_stopping_rounds':100, \n",
    "                } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data\n"
     ]
    }
   ],
   "source": [
    "print('Load data')\n",
    "train_df = pd.read_pickle(\"../input/df_train.pkl\")\n",
    "\n",
    "# We will prepare simulation here\n",
    "# Last month will be our test\n",
    "train_df['DT_M'] = train_df['TransactionDT'].apply(\n",
    "    lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n",
    "train_df['DT_M'] = (train_df['DT_M'].dt.year-2017)*12 + train_df['DT_M'].dt.month \n",
    "\n",
    "test_df = train_df[\n",
    "    train_df['DT_M'] == train_df['DT_M'].max()].reset_index(drop=True)\n",
    "train_df = train_df[\n",
    "    train_df['DT_M'] < train_df['DT_M'].max()].reset_index(drop=True)\n",
    "    \n",
    "print('Shape control:', train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    17\n",
       "1    17\n",
       "2    17\n",
       "3    17\n",
       "4    17\n",
       "Name: DT_M, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['DT_M'].head() # 원래 train에서 DT_M이 17(max, last month)인 것만 모음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12\n",
       "1    12\n",
       "2    12\n",
       "3    12\n",
       "4    12\n",
       "Name: DT_M, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['DT_M'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductCD\n",
      "card4\n",
      "card6\n",
      "P_emaildomain\n",
      "R_emaildomain\n",
      "M1\n",
      "M2\n",
      "M3\n",
      "M4\n",
      "M5\n",
      "M6\n",
      "M7\n",
      "M8\n",
      "M9\n",
      "id_12\n",
      "id_15\n",
      "id_16\n",
      "id_23\n",
      "id_27\n",
      "id_28\n",
      "id_29\n",
      "id_30\n",
      "id_31\n",
      "id_33\n",
      "id_34\n",
      "id_35\n",
      "id_36\n",
      "id_37\n",
      "id_38\n",
      "DeviceType\n",
      "DeviceInfo\n"
     ]
    }
   ],
   "source": [
    "# object data 타입 변경\n",
    "for col in list(train_df):\n",
    "    if train_df[col].dtype=='O':\n",
    "        print(col)\n",
    "        train_df[col] = train_df[col].fillna('unseen_before_label')\n",
    "        test_df[col]  = test_df[col].fillna('unseen_before_label')\n",
    "        \n",
    "        train_df[col] = train_df[col].astype(str)\n",
    "        test_df[col] = test_df[col].astype(str)\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train_df[col])+list(test_df[col]))\n",
    "        train_df[col] = le.transform(train_df[col])\n",
    "        test_df[col]  = le.transform(test_df[col])\n",
    "        \n",
    "        train_df[col] = train_df[col].astype('category')\n",
    "        test_df[col] = test_df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Some Features\n",
    "rm_cols = [\n",
    "    'TransactionID','TransactionDT', # These columns are pure noise right now\n",
    "    TARGET,                          # Not target in features))\n",
    "    'DT_M'                           # Column that we used to simulate test set\n",
    "]\n",
    "\n",
    "# Remove V columns (for faster training)\n",
    "rm_cols += ['V'+str(i) for i in range(1,340)] #V1 ~ V339 제외시킴\n",
    "# print(rm_cols)\n",
    "\n",
    "# Final features\n",
    "features_columns = [col for col in list(train_df) if col not in rm_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV(cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = test_df[['TransactionID',TARGET]]\n",
    "\n",
    "# We will always use same number of splits\n",
    "# for training model\n",
    "# Number of splits depends on data structure\n",
    "# and in our case it is better to use \n",
    "# something in range 5-10\n",
    "# 5 - is a common number of splits\n",
    "# 10+ is too much (we will not have enough diversity in data)\n",
    "# Here we will use 3 for faster training\n",
    "# but you can change it by yourself\n",
    "N_SPLITS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. No validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "No Validation training... 500 boosting rounds\n",
      "AUC score 0.9277271781014739\n",
      "####################\n",
      "####################\n",
      "No Validation training... 1000 boosting rounds\n",
      "AUC score 0.9326734191953692\n",
      "####################\n",
      "####################\n",
      "No Validation training... 2500 boosting rounds\n",
      "AUC score 0.9331337450590427\n",
      "####################\n",
      "####################\n",
      "No Validation training... 5000 boosting rounds\n",
      "AUC score 0.9306524679300963\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "# Main Data\n",
    "# We will take whole train data set\n",
    "# and will NOT use any early stopping \n",
    "X,y = train_df[features_columns], train_df[TARGET]\n",
    "\n",
    "# Test Data (what we need to predict)\n",
    "P = test_df[features_columns]\n",
    "\n",
    "# We don't know where to stop\n",
    "# so we will try to guess \n",
    "# number of boosting rounds\n",
    "for n_rounds in [500,1000,2500,5000]:\n",
    "    print('#'*20)\n",
    "    print('No Validation training...', n_rounds, 'boosting rounds')\n",
    "    corrected_lgb_params = lgb_params.copy()\n",
    "    corrected_lgb_params['n_estimators'] = n_rounds\n",
    "    corrected_lgb_params['early_stopping_rounds'] = None\n",
    "\n",
    "    train_data = lgb.Dataset(X, label=y)\n",
    "    \n",
    "    estimator = lgb.train(\n",
    "                corrected_lgb_params,\n",
    "                train_data\n",
    "            )\n",
    "\n",
    "    RESULTS['no_validation_'+str(n_rounds)] = estimator.predict(P)\n",
    "    print('AUC score', metrics.roc_auc_score(RESULTS[TARGET], RESULTS['no_validation_'+str(n_rounds)]))\n",
    "    print('#'*20)\n",
    "    \n",
    "# Be careful. We are printing auc results\n",
    "# for our simulated test set\n",
    "# but in real Data set we do not have True labels (obviously)\n",
    "# and can't be sure that we stopped in right round\n",
    "# lb probing can give you some idea how good our training is\n",
    "# but this leads to nowhere -> overfits or completely bad results\n",
    "# bad practice for real life problems!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "KFold training...\n",
      "Fold: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1000]\ttraining's auc: 0.998253\tvalid_1's auc: 0.959708\n",
      "[2000]\ttraining's auc: 0.99992\tvalid_1's auc: 0.962512\n",
      "[3000]\ttraining's auc: 0.999998\tvalid_1's auc: 0.963803\n",
      "[4000]\ttraining's auc: 1\tvalid_1's auc: 0.96462\n",
      "Early stopping, best iteration is:\n",
      "[4004]\ttraining's auc: 1\tvalid_1's auc: 0.964628\n",
      "Fold: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1000]\ttraining's auc: 0.998309\tvalid_1's auc: 0.957031\n",
      "[2000]\ttraining's auc: 0.999921\tvalid_1's auc: 0.960994\n",
      "[3000]\ttraining's auc: 0.999997\tvalid_1's auc: 0.962324\n",
      "[4000]\ttraining's auc: 1\tvalid_1's auc: 0.96288\n",
      "Early stopping, best iteration is:\n",
      "[4062]\ttraining's auc: 1\tvalid_1's auc: 0.962895\n",
      "Fold: 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1000]\ttraining's auc: 0.998342\tvalid_1's auc: 0.958528\n",
      "[2000]\ttraining's auc: 0.999929\tvalid_1's auc: 0.96149\n",
      "[3000]\ttraining's auc: 0.999997\tvalid_1's auc: 0.962714\n",
      "Early stopping, best iteration is:\n",
      "[3046]\ttraining's auc: 0.999998\tvalid_1's auc: 0.962763\n",
      "AUC score 0.9267082730385084\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "print('#'*20)\n",
    "print('KFold training...')\n",
    "\n",
    "# You can find oof name for this strategy\n",
    "# oof - Out Of Fold\n",
    "# as we will use one fold as validation\n",
    "# and stop training when validation metric\n",
    "# stops improve\n",
    "from sklearn.model_selection import KFold\n",
    "folds = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Main Data\n",
    "X,y = train_df[features_columns], train_df[TARGET]\n",
    "\n",
    "# Test Data\n",
    "P = test_df[features_columns]\n",
    "RESULTS['kfold'] = 0\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "    print('Fold:',fold_+1)\n",
    "    tr_x, tr_y = X.iloc[trn_idx,:], y[trn_idx]    \n",
    "    vl_x, v_y = X.iloc[val_idx,:], y[val_idx]    \n",
    "    train_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "    valid_data = lgb.Dataset(vl_x, label=v_y)  \n",
    "\n",
    "    estimator = lgb.train(\n",
    "            lgb_params,\n",
    "            train_data,\n",
    "            valid_sets = [train_data, valid_data],\n",
    "            verbose_eval = 1000,\n",
    "        )\n",
    "\n",
    "    RESULTS['kfold'] = estimator.predict(P)\n",
    "\n",
    "print('AUC score', metrics.roc_auc_score(RESULTS[TARGET], RESULTS['kfold']))\n",
    "print('#'*20)\n",
    "\n",
    "## We have two \"problems\" here\n",
    "## 1st: Training score goes upto 1 and it's not normal situation\n",
    "## It's nomally means that model did perfect or\n",
    "## almost perfect match between \"data fingerprint\" and target\n",
    "## we definitely should stop before to generalize better\n",
    "## 2nd: Our LB probing gave 0.936 and it is too far away from validation score\n",
    "## some difference is normal, but such gap is too big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Stratified KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('#'*20)\n",
    "print('StratifiedKFold training...')\n",
    "\n",
    "# Same as normal kfold but we can be sure\n",
    "# that our target is perfectly distribuited\n",
    "# over folds\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Main Data\n",
    "X,y = train_df[features_columns], train_df[TARGET]\n",
    "\n",
    "# Test Data and expport DF\n",
    "P = test_df[features_columns]\n",
    "RESULTS['stratifiedkfold'] = 0\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y, groups=y)):\n",
    "    print('Fold:',fold_+1)\n",
    "    tr_x, tr_y = X.iloc[trn_idx,:], y[trn_idx]    \n",
    "    vl_x, v_y = X.iloc[val_idx,:], y[val_idx]    \n",
    "    train_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "    valid_data = lgb.Dataset(vl_x, label=v_y)  \n",
    "\n",
    "    estimator = lgb.train(\n",
    "            lgb_params,\n",
    "            train_data,\n",
    "            valid_sets = [train_data, valid_data],\n",
    "            verbose_eval = 1000,\n",
    "        )\n",
    "\n",
    "    # we are not sure what fold is best for us\n",
    "    # so we will average prediction results \n",
    "    # over folds\n",
    "    RESULTS['stratifiedkfold'] += estimator.predict(P)/N_SPLITS\n",
    "\n",
    "print('AUC score', metrics.roc_auc_score(RESULTS[TARGET], RESULTS['stratifiedkfold']))\n",
    "print('#'*20)\n",
    "\n",
    "## We have same \"problems\" here as in normal kfold\n",
    "## 1st: Training score goes upto 1 and it's not normal situation\n",
    "## we definitely should stop before \n",
    "## 2nd: Our LB probing gave 0.936 and it is too far away from validation score\n",
    "## some difference is normal, but such gap is too big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. LBO (last block out)\n",
    "- 시계열의 경우 last time block을 validation subset으로 사용\n",
    "- track은 early stopping round 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "LBO training...\n"
     ]
    }
   ],
   "source": [
    "print('#'*20)\n",
    "print('LBO training...') \n",
    "\n",
    "## We need Divide Train Set by Time blocks\n",
    "## Convert TransactionDT to Months\n",
    "## And use last month as Validation\n",
    "train_df['DT_M'] = train_df['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n",
    "train_df['DT_M'] = (train_df['DT_M'].dt.year-2017)*12 + train_df['DT_M'].dt.month \n",
    "\n",
    "# 아래부터 주석 전체 제거!!\n",
    "# main_train_set = train_df[train_df['DT_M']<(train_df['DT_M'].max())].reset_index(drop=True)\n",
    "# validation_set = train_df[train_df['DT_M']==train_df['DT_M'].max()].reset_index(drop=True)\n",
    "\n",
    "# ## We will use oof kfold to find \"best round\"\n",
    "# folds = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# # Main Data\n",
    "# X,y = main_train_set[features_columns], main_train_set[TARGET]\n",
    "\n",
    "# # Validation Data\n",
    "# v_X, v_y = validation_set[features_columns], validation_set[TARGET]\n",
    "\n",
    "# estimators_bestround = []\n",
    "# for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "#     print('Fold:',fold_+1)\n",
    "#     tr_x, tr_y = X.iloc[trn_idx,:], y[trn_idx]    \n",
    "#     train_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "#     valid_data = lgb.Dataset(v_X, label=v_y)  \n",
    "\n",
    "#     estimator = lgb.train(\n",
    "#             lgb_params,\n",
    "#             train_data,\n",
    "#             valid_sets = [train_data, valid_data],\n",
    "#             verbose_eval = 1000,\n",
    "#         )\n",
    "#     estimators_bestround.append(estimator.current_iteration())\n",
    "\n",
    "# ## Now we have \"mean Best round\" and we can train model on full set\n",
    "# corrected_lgb_params = lgb_params.copy()\n",
    "# corrected_lgb_params['n_estimators'] = int(np.mean(estimators_bestround))\n",
    "# corrected_lgb_params['early_stopping_rounds'] = None\n",
    "# print('#'*10)\n",
    "# print('Mean Best round:', corrected_lgb_params['n_estimators'])\n",
    "\n",
    "# # Main Data\n",
    "# X,y = train_df[features_columns], train_df[TARGET]\n",
    "\n",
    "# # Test Data\n",
    "# P = test_df[features_columns]\n",
    "# RESULTS['lbo'] = 0\n",
    "\n",
    "# for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "#     print('Fold:',fold_+1)\n",
    "#     tr_x, tr_y = X.iloc[trn_idx,:], y[trn_idx]\n",
    "#     train_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "\n",
    "#     estimator = lgb.train(\n",
    "#             corrected_lgb_params,\n",
    "#             train_data\n",
    "#         )\n",
    "    \n",
    "#     RESULTS['lbo'] += estimator.predict(P)/N_SPLITS\n",
    "\n",
    "# print('AUC score', metrics.roc_auc_score(RESULTS[TARGET], RESULTS['lbo']))\n",
    "# print('#'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deeper analysis\n",
    "- n_estimators 2만 개는 너무 오래 걸려 2000개로 조정\n",
    "- 현재 no validation 2천, KFold 2만개 돌린 상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "Intermediate results...\n",
      "              Stategy    Result\n",
      "4  no_validation_2500  0.933134\n",
      "3  no_validation_1000  0.932673\n",
      "5  no_validation_5000  0.930652\n",
      "2   no_validation_500  0.927727\n",
      "0               kfold  0.926708\n",
      "1                DT_W  0.530529\n"
     ]
    }
   ],
   "source": [
    "# 일어나서 여기부터 실행!\n",
    "print('#'*30)\n",
    "print('Intermediate results...')\n",
    "final_df = []\n",
    "for current_strategy in list(RESULTS.iloc[:,2:]):\n",
    "    auc_score = metrics.roc_auc_score(RESULTS[TARGET], RESULTS[current_strategy])\n",
    "    final_df.append([current_strategy, auc_score])\n",
    "    \n",
    "final_df = pd.DataFrame(final_df, columns=['Stategy', 'Result'])\n",
    "final_df.sort_values(by=['Result'], ascending=False, inplace=True)\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Time Block: 70\n",
      "              Stategy    Result\n",
      "5  no_validation_5000  0.950372\n",
      "4  no_validation_2500  0.950023\n",
      "3  no_validation_1000  0.945684\n",
      "0               kfold  0.941175\n",
      "2   no_validation_500  0.936770\n",
      "1                DT_W  0.500000\n",
      "##############################\n",
      "####################\n",
      "Time Block: 71\n",
      "              Stategy    Result\n",
      "4  no_validation_2500  0.928660\n",
      "3  no_validation_1000  0.928077\n",
      "5  no_validation_5000  0.924845\n",
      "2   no_validation_500  0.924023\n",
      "0               kfold  0.922592\n",
      "1                DT_W  0.500000\n",
      "##############################\n",
      "####################\n",
      "Time Block: 72\n",
      "              Stategy    Result\n",
      "3  no_validation_1000  0.925413\n",
      "4  no_validation_2500  0.925350\n",
      "5  no_validation_5000  0.922881\n",
      "2   no_validation_500  0.921449\n",
      "0               kfold  0.919267\n",
      "1                DT_W  0.500000\n",
      "##############################\n",
      "####################\n",
      "Time Block: 73\n",
      "              Stategy    Result\n",
      "3  no_validation_1000  0.935728\n",
      "4  no_validation_2500  0.934994\n",
      "5  no_validation_5000  0.931855\n",
      "2   no_validation_500  0.931521\n",
      "0               kfold  0.929685\n",
      "1                DT_W  0.500000\n",
      "##############################\n",
      "####################\n",
      "Time Block: 74\n",
      "              Stategy    Result\n",
      "3  no_validation_1000  0.926698\n",
      "4  no_validation_2500  0.924780\n",
      "2   no_validation_500  0.923474\n",
      "5  no_validation_5000  0.921158\n",
      "0               kfold  0.919203\n",
      "1                DT_W  0.500000\n",
      "##############################\n"
     ]
    }
   ],
   "source": [
    "test_df['DT_W'] = test_df['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n",
    "RESULTS['DT_W'] = (test_df['DT_W'].dt.year-2017)*52 + test_df['DT_W'].dt.weekofyear \n",
    "\n",
    "for curent_time_block in range(RESULTS['DT_W'].min(), RESULTS['DT_W'].max()+1):\n",
    "    print('#'*20)\n",
    "    print('Time Block:', curent_time_block)\n",
    "    final_df = []\n",
    "    temp_df = RESULTS[RESULTS['DT_W']==curent_time_block]\n",
    "    for current_strategy in list(temp_df.iloc[:,2:]):\n",
    "        auc_score = metrics.roc_auc_score(temp_df[TARGET], temp_df[current_strategy])\n",
    "        final_df.append([current_strategy, auc_score])\n",
    "    \n",
    "    final_df = pd.DataFrame(final_df, columns=['Stategy', 'Result'])\n",
    "    final_df.sort_values(by=['Result'], ascending=False, inplace=True)\n",
    "    print(final_df)\n",
    "    print('#'*30)\n",
    "    \n",
    "# Naive analize.\n",
    "# But we can see temporal auc degradation\n",
    "# Probably for test set with larger monthly gap\n",
    "# from training set we need to use less boosting rounds (or more)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stategy</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no_validation_1000</td>\n",
       "      <td>0.926698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no_validation_2500</td>\n",
       "      <td>0.924780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no_validation_500</td>\n",
       "      <td>0.923474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>no_validation_5000</td>\n",
       "      <td>0.921158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kfold</td>\n",
       "      <td>0.919203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT_W</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Stategy    Result\n",
       "3  no_validation_1000  0.926698\n",
       "4  no_validation_2500  0.924780\n",
       "2   no_validation_500  0.923474\n",
       "5  no_validation_5000  0.921158\n",
       "0               kfold  0.919203\n",
       "1                DT_W  0.500000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그래서 결과는 어느 변수에 저장되는 건지???\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
